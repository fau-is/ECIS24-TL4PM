{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b6fa5ac-f15f-4d10-a7cb-b4310c563436",
   "metadata": {},
   "source": [
    "# Experiments with temporal sorted data split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e44dbc-9b0e-4565-9b05-1b05f1d67c01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import pickle as pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from src.trainer import CaseDataSet\n",
    "from src.model import DLModels\n",
    "from src.trainer import Trainer\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "import importlib.util\n",
    "torch_device = \"cpu\"\n",
    "device_package = torch.cpu\n",
    "if importlib.util.find_spec(\"torch.backends.mps\") is not None:\n",
    "    if torch.backends.mps.is_available():\n",
    "        torch_device = torch.device(\"mps\")\n",
    "        device_package = torch.mps\n",
    "if torch.cuda.is_available():\n",
    "    torch_device = torch.device(\"cuda\")\n",
    "    device_package = torch.cuda\n",
    "    \n",
    "torch_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9b0e42c-feef-4c4e-bfc0-c65b4b0bf9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_source_model(datasets_dict, model_hyper_para, trainer_hyper_para,\n",
    "                       split, embedding, print_iter=False, file_suffix=\"\"):\n",
    "    torch_device = \"cpu\"\n",
    "    device_package = torch.cpu\n",
    "    if importlib.util.find_spec(\"torch.backends.mps\") is not None:\n",
    "        if torch.backends.mps.is_available():\n",
    "            torch_device = torch.device(\"mps\")\n",
    "            device_package = torch.mps\n",
    "    if torch.cuda.is_available():\n",
    "        torch_device = torch.device(\"cuda\")\n",
    "        device_package = torch.cuda\n",
    "        \n",
    "    current_model_para = model_hyper_para[embedding]\n",
    "    # Instantiate the model\n",
    "    model = DLModels.SimpleLSTM(current_model_para[\"input_size\"],\n",
    "                                current_model_para[\"hidden_size\"],\n",
    "                                current_model_para[\"num_layers\"],\n",
    "                                1).to(torch_device)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=trainer_hyper_para[\"learning_rate\"])\n",
    "    \n",
    "    # Load data sets\n",
    "    source_data_sets = datasets_dict[split][embedding][\"source\"]\n",
    "    \n",
    "\n",
    "    \n",
    "    print(torch_device)\n",
    "    print(\"training model with target data\")\n",
    "    model_source, train_loss_source, val_loss_srouce = Trainer.train_model(model, optimizer,\n",
    "                                                                           None, None,\n",
    "                                                                           source_data_sets[\"train\"],\n",
    "                                                                           source_data_sets[\"val\"],\n",
    "                                                                           trainer_hyper_para[\"batch_size\"],\n",
    "                                                                           torch_device,\n",
    "                                                                           device_package,\n",
    "                                                                           Trainer.prefix_weighted_loss,\n",
    "                                                                           trainer_hyper_para[\"max_epoch\"],\n",
    "                                                                           trainer_hyper_para[\"max_ob_iter\"],\n",
    "                                                                           trainer_hyper_para[\"score_margin\"],\n",
    "                                                                           print_iter=print_iter)\n",
    "    \n",
    "    \n",
    "    model_name = \"LSTM_S_h\" + str(current_model_para[\"hidden_size\"]) + \"_l\" + str(current_model_para[\"num_layers\"]) + \"_\" + embedding\n",
    "    torch.save(model_source, \"../../Model/\" + split + \"/LSTM/\"+ model_name + \"_\" +  file_suffix + \".LSTM\")\n",
    "    \n",
    "    training_stat = pd.DataFrame(columns=[\"TrainingLoss\", \"ValidationLoss\"],\n",
    "                                 data=np.hstack([train_loss_source.reshape((-1, 1)),\n",
    "                                                 val_loss_srouce.reshape((-1, 1))]))\n",
    "    training_stat.to_pickle(\"../../Model/\" + split + \"/LSTM/\"+ model_name + \"_\" + file_suffix + \"_stat.pkl\")\n",
    "    \n",
    "    \n",
    "    print(\"Finished training model with target data\")\n",
    "    \n",
    "def train_target_model(datasets_dict, model_hyper_para, trainer_hyper_para,\n",
    "                       split, embedding, print_iter=False, file_suffix=\"\"):\n",
    "    torch_device = \"cpu\"\n",
    "    device_package = torch.cpu\n",
    "    if importlib.util.find_spec(\"torch.backends.mps\") is not None:\n",
    "        if torch.backends.mps.is_available():\n",
    "            torch_device = torch.device(\"mps\")\n",
    "            device_package = torch.mps\n",
    "    if torch.cuda.is_available():\n",
    "        torch_device = torch.device(\"cuda\")\n",
    "        device_package = torch.cuda\n",
    "        \n",
    "    current_model_para = model_hyper_para[embedding]\n",
    "    # Instantiate the model\n",
    "    model = DLModels.SimpleLSTM(current_model_para[\"input_size\"],\n",
    "                                current_model_para[\"hidden_size\"],\n",
    "                                current_model_para[\"num_layers\"],\n",
    "                                1).to(torch_device)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=trainer_hyper_para[\"learning_rate\"])\n",
    "    \n",
    "    # Load data sets\n",
    "    data_sets = datasets_dict[split][embedding][\"target\"]\n",
    "    \n",
    "\n",
    "    \n",
    "    print(torch_device)\n",
    "    print(\"training model with target data\")\n",
    "    model_source, train_loss_source, val_loss_srouce = Trainer.train_model(model, optimizer,\n",
    "                                                                           None, None,\n",
    "                                                                           data_sets[\"train\"],\n",
    "                                                                           data_sets[\"val\"],\n",
    "                                                                           4000,\n",
    "                                                                           torch_device,\n",
    "                                                                           device_package,\n",
    "                                                                           Trainer.prefix_weighted_loss,\n",
    "                                                                           trainer_hyper_para[\"max_epoch\"],\n",
    "                                                                           trainer_hyper_para[\"max_ob_iter\"],\n",
    "                                                                           trainer_hyper_para[\"score_margin\"],\n",
    "                                                                           print_iter=print_iter)\n",
    "    \n",
    "    \n",
    "    model_name = \"LSTM_T_h\" + str(current_model_para[\"hidden_size\"]) + \"_l\" + str(current_model_para[\"num_layers\"]) + \"_\" + embedding\n",
    "    torch.save(model_source, \"../../Model/\" + split + \"/LSTM/\"+ model_name + \"_\" +  file_suffix + \".LSTM\")\n",
    "    \n",
    "    training_stat = pd.DataFrame(columns=[\"TrainingLoss\", \"ValidationLoss\"],\n",
    "                                 data=np.hstack([train_loss_source.reshape((-1, 1)),\n",
    "                                                 val_loss_srouce.reshape((-1, 1))]))\n",
    "    training_stat.to_pickle(\"../../Model/\" + split + \"/LSTM/\"+ model_name + \"_\" + file_suffix + \"_stat.pkl\")\n",
    "    \n",
    "    \n",
    "    print(\"Finished training model with target data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9225a0b0-4e35-481c-ac85-571550cf36de",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_stat = pd.read_pickle(\"../../Model/641620split/LSTM/LSTM_S_h512_l1_st_stat.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fc9f4d8-56c2-4ee5-bac8-9864dc540ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_hyper_para = {\"max_epoch\": 100,\n",
    "                      \"max_ob_iter\": 20,\n",
    "                      \"score_margin\": 1,\n",
    "                      \"num_class\": 1,\n",
    "                      \"num_layers\": 1,\n",
    "                      \"learning_rate\": 1e-3,\n",
    "                      \"batch_size\": 50,\n",
    "                      \"training_loss_func\": \"CCM\",\n",
    "                      \"eval_loss_func\": \"CCM\"}\n",
    "\n",
    "model_hyper_para = {\"w2v\": {\"input_size\": 51,\n",
    "                            \"hidden_size\": 128,\n",
    "                            \"num_layers\": 1},\n",
    "                    \"st\": {\"input_size\": 385,\n",
    "                           \"hidden_size\": 512,\n",
    "                           \"num_layers\": 1},\n",
    "                    \"onehot\": {\"input_size\": 48,\n",
    "                               \"hidden_size\": 128,\n",
    "                               \"num_layers\": 1}}\n",
    "\n",
    "\n",
    "split_pattern = [\"811split\", \"641620split\"]\n",
    "data_set_type = [\"source\", \"target\"]\n",
    "data_set_cat = [\"train\", \"val\", \"test\"]\n",
    "embedding_type = [\"w2v\", \"st\", \"onehot\"]\n",
    "dataset_list_index = [split_pattern, embedding_type, data_set_type, data_set_cat]\n",
    "\n",
    "earliness_requirement = True\n",
    "folder_path = \"../../Data/Training/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abd46da1-9dab-4164-9af6-d5bfa581b0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sets_list = {}\n",
    "for s_pattern in split_pattern:\n",
    "    data_split_list = {}\n",
    "    for embedding in embedding_type:\n",
    "        data_embedding_list = {}\n",
    "        for d_type in data_set_type:\n",
    "            data_type_list = {}\n",
    "            for d_cat in data_set_cat:       \n",
    "                data_version = \"_\" + d_cat + \"_sorted\"\n",
    "                embedding_version = \"_\" + embedding\n",
    "                case_data_set = CaseDataSet.CaseDataset(split_pattern=s_pattern,\n",
    "                                                        input_data=d_type,\n",
    "                                                        data_version=data_version,\n",
    "                                                        embedding_version=embedding_version,\n",
    "                                                        earliness_requirement=earliness_requirement)\n",
    "                \n",
    "                data_type_list[d_cat] = case_data_set\n",
    "            data_embedding_list[d_type] = data_type_list\n",
    "        data_split_list[embedding] = data_embedding_list\n",
    "    data_sets_list[s_pattern] = data_split_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c3fe0b0-8589-4a4e-8868-f9c7ca8b8ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "training model with target data\n",
      "Finished training model with target data\n",
      "cuda\n",
      "training model with target data\n",
      "Finished training model with target data\n",
      "cuda\n",
      "training model with target data\n",
      "Finished training model with target data\n",
      "cuda\n",
      "training model with target data\n",
      "Finished training model with target data\n",
      "cuda\n",
      "training model with target data\n",
      "Finished training model with target data\n",
      "cuda\n",
      "training model with target data\n",
      "Finished training model with target data\n",
      "cuda\n",
      "training model with target data\n",
      "Finished training model with target data\n",
      "cuda\n",
      "training model with target data\n",
      "Finished training model with target data\n",
      "cuda\n",
      "training model with target data\n",
      "Finished training model with target data\n",
      "cuda\n",
      "training model with target data\n",
      "Finished training model with target data\n",
      "cuda\n",
      "training model with target data\n",
      "Finished training model with target data\n",
      "cuda\n",
      "training model with target data\n",
      "Finished training model with target data\n",
      "cuda\n",
      "training model with target data\n",
      "Finished training model with target data\n",
      "cuda\n",
      "training model with target data\n",
      "Finished training model with target data\n",
      "cuda\n",
      "training model with target data\n",
      "Finished training model with target data\n",
      "cuda\n",
      "training model with target data\n",
      "Finished training model with target data\n",
      "cuda\n",
      "training model with target data\n",
      "Finished training model with target data\n",
      "cuda\n",
      "training model with target data\n",
      "Finished training model with target data\n",
      "cuda\n",
      "training model with target data\n",
      "Finished training model with target data\n",
      "cuda\n",
      "training model with target data\n",
      "Finished training model with target data\n",
      "cuda\n",
      "training model with target data\n",
      "Finished training model with target data\n",
      "cuda\n",
      "training model with target data\n",
      "Finished training model with target data\n",
      "cuda\n",
      "training model with target data\n",
      "Finished training model with target data\n",
      "cuda\n",
      "training model with target data\n",
      "Finished training model with target data\n",
      "cuda\n",
      "training model with target data\n",
      "Finished training model with target data\n",
      "cuda\n",
      "training model with target data\n",
      "Finished training model with target data\n",
      "cuda\n",
      "training model with target data\n",
      "Finished training model with target data\n",
      "cuda\n",
      "training model with target data\n",
      "Finished training model with target data\n",
      "cuda\n",
      "training model with target data\n",
      "Finished training model with target data\n",
      "cuda\n",
      "training model with target data\n",
      "Finished training model with target data\n",
      "cuda\n",
      "training model with target data\n",
      "Finished training model with target data\n",
      "cuda\n",
      "training model with target data\n",
      "Finished training model with target data\n",
      "cuda\n",
      "training model with target data\n",
      "Finished training model with target data\n",
      "cuda\n",
      "training model with target data\n",
      "Finished training model with target data\n",
      "cuda\n",
      "training model with target data\n",
      "Finished training model with target data\n",
      "cuda\n",
      "training model with target data\n",
      "Finished training model with target data\n",
      "cuda\n",
      "training model with target data\n",
      "Finished training model with target data\n",
      "cuda\n",
      "training model with target data\n",
      "Finished training model with target data\n",
      "cuda\n",
      "training model with target data\n",
      "Finished training model with target data\n",
      "cuda\n",
      "training model with target data\n",
      "Finished training model with target data\n",
      "cuda\n",
      "training model with target data\n",
      "Finished training model with target data\n",
      "cuda\n",
      "training model with target data\n",
      "Finished training model with target data\n",
      "cuda\n",
      "training model with target data\n",
      "Finished training model with target data\n",
      "cuda\n",
      "training model with target data\n",
      "Finished training model with target data\n",
      "cuda\n",
      "training model with target data\n",
      "Finished training model with target data\n",
      "cuda\n",
      "training model with target data\n",
      "Finished training model with target data\n",
      "cuda\n",
      "training model with target data\n",
      "Finished training model with target data\n",
      "cuda\n",
      "training model with target data\n",
      "Finished training model with target data\n",
      "cuda\n",
      "training model with target data\n",
      "Finished training model with target data\n",
      "cuda\n",
      "training model with target data\n",
      "Finished training model with target data\n",
      "cuda\n",
      "training model with target data\n",
      "Finished training model with target data\n",
      "cuda\n",
      "training model with target data\n",
      "Finished training model with target data\n",
      "cuda\n",
      "training model with target data\n",
      "Finished training model with target data\n",
      "cuda\n",
      "training model with target data\n",
      "Finished training model with target data\n",
      "cuda\n",
      "training model with target data\n",
      "Finished training model with target data\n",
      "cuda\n",
      "training model with target data\n",
      "Finished training model with target data\n",
      "cuda\n",
      "training model with target data\n",
      "Finished training model with target data\n",
      "cuda\n",
      "training model with target data\n",
      "Finished training model with target data\n",
      "cuda\n",
      "training model with target data\n",
      "Finished training model with target data\n",
      "cuda\n",
      "training model with target data\n",
      "Finished training model with target data\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    train_source_model(data_sets_list, model_hyper_para, trainer_hyper_para,\n",
    "                       split=\"641620split\", embedding=\"w2v\", print_iter=False, file_suffix=str(i))\n",
    "    train_source_model(data_sets_list, model_hyper_para, trainer_hyper_para,\n",
    "                       split=\"641620split\", embedding=\"st\", print_iter=False, file_suffix=str(i))\n",
    "    train_source_model(data_sets_list, model_hyper_para, trainer_hyper_para,\n",
    "                       split=\"641620split\", embedding=\"onehot\", print_iter=False, file_suffix=str(i))\n",
    "    train_target_model(data_sets_list, model_hyper_para, trainer_hyper_para,\n",
    "                       split=\"641620split\", embedding=\"w2v\", print_iter=False, file_suffix=str(i))\n",
    "    train_target_model(data_sets_list, model_hyper_para, trainer_hyper_para,\n",
    "                       split=\"641620split\", embedding=\"onehot\", print_iter=False, file_suffix=str(i))\n",
    "    train_target_model(data_sets_list, model_hyper_para, trainer_hyper_para,\n",
    "                       split=\"641620split\", embedding=\"st\", print_iter=False, file_suffix=str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23184d0a-a360-4652-b60e-79fe85663c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "training model with target data\n",
      "Finished training iteration:  0  with val loss:  2037.6947858247484  train loss:  4621.937561457762\n",
      "Finished training iteration:  1  with val loss:  2117.900303688917  train loss:  4698.674602248174\n",
      "Finished training iteration:  2  with val loss:  2219.5506409357904  train loss:  4802.460654858565\n",
      "Finished training iteration:  3  with val loss:  2067.208663561274  train loss:  4934.881693740298\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_target_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_sets_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_hyper_para\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainer_hyper_para\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                   \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m641620split\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43monehot\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_suffix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mb2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 82\u001b[0m, in \u001b[0;36mtrain_target_model\u001b[0;34m(datasets_dict, model_hyper_para, trainer_hyper_para, split, embedding, print_iter, file_suffix)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28mprint\u001b[39m(torch_device)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining model with target data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 82\u001b[0m model_source, train_loss_source, val_loss_srouce \u001b[38;5;241m=\u001b[39m \u001b[43mTrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m                                                                       \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m                                                                       \u001b[49m\u001b[43mdata_sets\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m                                                                       \u001b[49m\u001b[43mdata_sets\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mval\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m                                                                       \u001b[49m\u001b[38;5;241;43m4000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m                                                                       \u001b[49m\u001b[43mtorch_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m                                                                       \u001b[49m\u001b[43mdevice_package\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m                                                                       \u001b[49m\u001b[43mTrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprefix_weighted_loss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m                                                                       \u001b[49m\u001b[43mtrainer_hyper_para\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_epoch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m                                                                       \u001b[49m\u001b[43mtrainer_hyper_para\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_ob_iter\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m                                                                       \u001b[49m\u001b[43mtrainer_hyper_para\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore_margin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m                                                                       \u001b[49m\u001b[43mprint_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprint_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLSTM_T_h\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(current_model_para[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhidden_size\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_l\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(current_model_para[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_layers\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m embedding\n\u001b[1;32m     97\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(model_source, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../Model/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m split \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/LSTM/\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m model_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m  file_suffix \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.LSTM\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Projects/ECIS24-TL4PM/src/trainer/Trainer.py:85\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, optimizer, criterion, criterion_eval, training_set, val_set, batch_size, torch_device, device_package, eval_func, max_epoch, max_ob_iter, score_margin, print_iter)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m iter_epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_epoch):\n\u001b[1;32m     84\u001b[0m     device_package\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[0;32m---> 85\u001b[0m     loss_train, sample_num_train \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch_device\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_device\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m     device_package\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[1;32m     88\u001b[0m     loss_val, sample_num_val \u001b[38;5;241m=\u001b[39m train_model_epoch(model, val_set, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[1;32m     89\u001b[0m                                                  criterion\u001b[38;5;241m=\u001b[39mcriterion_eval, torch_device\u001b[38;5;241m=\u001b[39mtorch_device, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Projects/ECIS24-TL4PM/src/trainer/Trainer.py:50\u001b[0m, in \u001b[0;36mtrain_model_epoch\u001b[0;34m(model, training_set, optimizer, criterion, torch_device, batch_size, training)\u001b[0m\n\u001b[1;32m     48\u001b[0m training_data_set\u001b[38;5;241m.\u001b[39mset_prefix_length(prefix_len)\n\u001b[1;32m     49\u001b[0m training_data_set\u001b[38;5;241m.\u001b[39mshuffle_data()\n\u001b[0;32m---> 50\u001b[0m input_data \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_data_set\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;66;03m# print(\"Max length reached, abort\")\u001b[39;00m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/ECIS24-TL4PM/src/trainer/CaseDataSet.py:75\u001b[0m, in \u001b[0;36mCaseDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_tensor(idx):\n\u001b[1;32m     73\u001b[0m     idx \u001b[38;5;241m=\u001b[39m idx\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m---> 75\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mdata_temp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFeature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_feature_vec_np\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mvalues[idx]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     76\u001b[0m y \u001b[38;5;241m=\u001b[39m data_temp[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLabel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[idx]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(x) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m :\n",
      "File \u001b[0;32m~/anaconda3/envs/tl4pm/lib/python3.8/site-packages/pandas/core/series.py:4630\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4520\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4521\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4522\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4525\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4526\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4527\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4528\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4529\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4628\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4629\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4630\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tl4pm/lib/python3.8/site-packages/pandas/core/apply.py:1025\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;66;03m# self.f is Callable\u001b[39;00m\n\u001b[0;32m-> 1025\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tl4pm/lib/python3.8/site-packages/pandas/core/apply.py:1076\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1074\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1075\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m-> 1076\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1077\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1078\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1079\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1080\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1082\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1083\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/anaconda3/envs/tl4pm/lib/python3.8/site-packages/pandas/_libs/lib.pyx:2834\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Projects/ECIS24-TL4PM/src/trainer/CaseDataSet.py:63\u001b[0m, in \u001b[0;36mCaseDataset.convert_feature_vec_np\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_feature_vec_np\u001b[39m(\u001b[38;5;28mself\u001b[39m, data):\n\u001b[1;32m     62\u001b[0m     data_tmp \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack(data[:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprefix_length])\n\u001b[0;32m---> 63\u001b[0m     data_output \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_tmp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data_output\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_target_model(data_sets_list, model_hyper_para, trainer_hyper_para,\n",
    "                   split=\"641620split\", embedding=\"onehot\", print_iter=True, file_suffix=\"b2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
