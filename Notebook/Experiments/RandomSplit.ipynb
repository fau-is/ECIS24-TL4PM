{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33f8c240-29eb-47cf-9aa1-0d3d1f6b9741",
   "metadata": {},
   "source": [
    "# Experiments with random split of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5604a47-1bbb-43db-9846-de5477750713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import pickle as pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from src.trainer import CaseDataSet\n",
    "from src.model import DLModels\n",
    "from src.trainer import Trainer\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "import importlib.util\n",
    "torch_device = \"cpu\"\n",
    "device_package = torch.cpu\n",
    "if importlib.util.find_spec(\"torch.backends.mps\") is not None:\n",
    "    if torch.backends.mps.is_available():\n",
    "        torch_device = torch.device(\"mps\")\n",
    "        device_package = torch.mps\n",
    "if torch.cuda.is_available():\n",
    "    torch_device = torch.device(\"cuda\")\n",
    "    device_package = torch.cuda\n",
    "    \n",
    "torch_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89e78421-c91d-400b-86b8-5a15fdf08439",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_pattern = [\"811split\", \"641620split\"]\n",
    "data_set_type = [\"source\", \"target\"]\n",
    "data_set_cat = [\"train\", \"val\", \"test\"]\n",
    "embedding_type = [\"w2v\", \"st\", \"onehot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14fddd2f-20b9-46fc-8b36-962a43d58737",
   "metadata": {},
   "outputs": [],
   "source": [
    "earliness_requirement = True\n",
    "folder_path = \"../../Data/Training/\"\n",
    "data_sets_list = {}\n",
    "for s_pattern in split_pattern:\n",
    "    data_split_list = {}\n",
    "    for embedding in embedding_type:\n",
    "        data_embedding_list = {}\n",
    "        for d_type in data_set_type:\n",
    "            data_type_list = {}\n",
    "            for d_cat in data_set_cat:       \n",
    "           \n",
    "                data_version = \"_\" + d_cat + \"_random\"\n",
    "                embedding_version = \"_\" + embedding\n",
    "                case_data_set = CaseDataSet.CaseDataset(split_pattern=s_pattern,\n",
    "                                                        input_data=d_type,\n",
    "                                                        data_version=data_version,\n",
    "                                                        embedding_version=embedding_version,\n",
    "                                                        earliness_requirement=earliness_requirement)\n",
    "                \n",
    "                data_type_list[d_cat] = case_data_set\n",
    "            data_embedding_list[d_type] = data_type_list\n",
    "        data_split_list[embedding] = data_embedding_list\n",
    "    data_sets_list[s_pattern] = data_split_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4eff6155-79c5-4aaf-b374-306b120b0963",
   "metadata": {},
   "outputs": [],
   "source": [
    "for s_pattern in split_pattern:\n",
    "    data_set_split = data_sets_list[s_pattern] \n",
    "    data_set_embedding = data_set_split[\"w2v\"]\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7aaaf39-f151-4fa3-bf2c-6bb98837131f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': {'train': <src.trainer.CaseDataSet.CaseDataset at 0x15eb041ffa0>,\n",
       "  'val': <src.trainer.CaseDataSet.CaseDataset at 0x15eb0437310>,\n",
       "  'test': <src.trainer.CaseDataSet.CaseDataset at 0x15eb0437490>},\n",
       " 'target': {'train': <src.trainer.CaseDataSet.CaseDataset at 0x15ed0f0b1c0>,\n",
       "  'val': <src.trainer.CaseDataSet.CaseDataset at 0x15ead266fa0>,\n",
       "  'test': <src.trainer.CaseDataSet.CaseDataset at 0x15ead27fbe0>}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "input_size = 51  # The number of expected features in the input x\n",
    "hidden_size = 128  # The number of features in the hidden state h\n",
    "num_layers = 1  # Number of recurrent layers\n",
    "num_classes = 1  # For binary classification\n",
    "learning_rate = 0.001\n",
    "batch_size = 1000\n",
    "\n",
    "# Instantiate the model\n",
    "model = DLModels.SimpleLSTM(input_size, hidden_size, num_layers, num_classes).to(torch_device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "model, train_loss, val_loss = Trainer.train_model(model, optimizer, None, None, source_train, source_val, batch_size,\n",
    "                                          torch_device, device_package, eval_func=prefix_weighted_loss,\n",
    "                                          max_epoch=50, max_ob_iter=20, score_margin=1e-4, print_iter=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
