{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ca7ac95-f930-46ba-b83d-ec232e80dfd8",
   "metadata": {},
   "source": [
    "# Hyper Parameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f06acb7d-ee3b-44a0-9031-098fab153f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ap43owus/anaconda3/envs/tl4pm/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from src.trainer import Trainer\n",
    "from src.trainer import CaseDataSet\n",
    "from src.model import DLModels\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import optuna\n",
    "import importlib.util\n",
    "import joblib\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "732c3eae-1cc4-41dd-a3f8-64da4ddb624d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_hyper_para = {\"max_epoch\": 100,\n",
    "                      \"max_ob_iter\": 20,\n",
    "                      \"score_margin\": 1,\n",
    "                      \"num_class\": 1,\n",
    "                      \"num_layers\": 1,\n",
    "                      \"learning_rate\": 1e-3,\n",
    "                      \"batch_size\": 1000,\n",
    "                      \"training_loss_func\": \"CCM\",\n",
    "                      \"eval_loss_func\": \"CCM\"}\n",
    "\n",
    "model_hyper_para = {\"w2v\": {\"input_size\": 51,\n",
    "                            \"hidden_size\": 128,\n",
    "                            \"num_layers\": 1},\n",
    "                    \"st\": {\"input_size\": 385,\n",
    "                           \"hidden_size\": 512,\n",
    "                           \"num_layers\": 1},\n",
    "                    \"onehot\": {\"input_size\": 48,\n",
    "                               \"hidden_size\": 128,\n",
    "                               \"num_layers\": 1}}\n",
    "\n",
    "\n",
    "split_pattern = [\"811split\", \"641620split\"]\n",
    "data_set_type = [\"source\", \"target\"]\n",
    "data_set_cat = [\"train\", \"val\", \"test\"]\n",
    "embedding_type = [\"w2v\", \"st\", \"onehot\"]\n",
    "dataset_list_index = [split_pattern, embedding_type, data_set_type, data_set_cat]\n",
    "\n",
    "earliness_requirement = True\n",
    "folder_path = \"../../Data/Training/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6beaa04a-c783-4af2-8640-2eb6133f1643",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_torch_device():\n",
    "    torch_device = \"cpu\"\n",
    "    device_package = torch.cpu\n",
    "    if importlib.util.find_spec(\"torch.backends.mps\") is not None:\n",
    "        if torch.backends.mps.is_available():\n",
    "            torch_device = torch.device(\"mps\")\n",
    "            device_package = torch.mps\n",
    "    if torch.cuda.is_available():\n",
    "        torch_device = torch.device(\"cuda\")\n",
    "        device_package = torch.cuda\n",
    "    return torch_device, device_package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36bb2957-c382-4970-b63c-1ca90167f5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_device, device_package = get_torch_device()\n",
    "\n",
    "train_set = CaseDataSet.CaseDataset(split_pattern=\"641620split\", input_data=\"source\",\n",
    "                                    data_version=\"_train_sorted\", embedding_version=\"_st\",\n",
    "                                    earliness_requirement=earliness_requirement)\n",
    "\n",
    "\n",
    "val_set = CaseDataSet.CaseDataset(split_pattern=\"641620split\", input_data=\"source\",\n",
    "                                  data_version=\"_val_sorted\", embedding_version=\"_st\",\n",
    "                                  earliness_requirement=earliness_requirement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5336d234-e5d6-4041-968a-f68974aca4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Hyperparameters\n",
    "    input_size = 385  # The number of expected features in the input x\n",
    "    hidden_size = trial.suggest_int(\"n_hidden\", 4, 512)  # The number of features in the hidden state h\n",
    "    num_layers = trial.suggest_int(\"n_layer\", 1, 4)  # Number of recurrent layers\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 10, 10000)\n",
    "    num_classes = 1  # For binary classification\n",
    "    learning_rate = 0.001\n",
    "\n",
    "    model = DLModels.SimpleLSTM(input_size, hidden_size, num_layers, num_classes).to(torch_device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    model, train_loss_source, val_loss_srouce = Trainer.train_model(model, optimizer,\n",
    "                                                                   None, None,\n",
    "                                                                   train_set,\n",
    "                                                                   val_set,\n",
    "                                                                   batch_size,\n",
    "                                                                   torch_device,\n",
    "                                                                   device_package,\n",
    "                                                                   Trainer.prefix_weighted_loss,\n",
    "                                                                   trainer_hyper_para[\"max_epoch\"],\n",
    "                                                                   trainer_hyper_para[\"max_ob_iter\"],\n",
    "                                                                   trainer_hyper_para[\"score_margin\"],\n",
    "                                                                   print_iter=False)\n",
    "    \n",
    "    \n",
    "    model.flatten()\n",
    "    roc_auc, f1, f1_inverse, precision, precision_inverse, recall, recall_inverse = Trainer.eval_model(model, val_set,\n",
    "                                                                                                           torch_device=torch_device,\n",
    "                                                                                                           device_package=device_package)\n",
    "    model_name = \"LSTM_S_h\" + str(hidden_size) + \"_l\" + str(num_layers) + \"_st\"\n",
    "    torch.save(model, \"../../Model/Optuna/641620split/LSTM/\"+ model_name + \".LSTM\")\n",
    "    \n",
    "    training_stat = pd.DataFrame(columns=[\"TrainingLoss\", \"ValidationLoss\"],\n",
    "                                 data=np.hstack([train_loss_source.reshape((-1, 1)),\n",
    "                                                 val_loss_srouce.reshape((-1, 1))]))\n",
    "    training_stat.to_pickle(\"../../Model/Optuna/641620split/LSTM/\"+ model_name + \"_S_st_stat.pkl\")\n",
    "    \n",
    "    del model\n",
    "    device_package.empty_cache()\n",
    "    return roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1261a9e0-e675-4ebc-92ed-fffb30d64f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-20 12:45:53,923] A new study created in memory with name: no-name-5230a196-1e6d-4eb4-ae2d-1fc77bc4fbf8\n",
      "[I 2024-03-20 12:56:24,427] Trial 0 finished with value: 0.71385180313697 and parameters: {'n_hidden': 466, 'n_layer': 4, 'batch_size': 3989}. Best is trial 0 with value: 0.71385180313697.\n",
      "[I 2024-03-20 13:13:04,978] Trial 1 finished with value: 0.7452219090403807 and parameters: {'n_hidden': 175, 'n_layer': 3, 'batch_size': 9844}. Best is trial 1 with value: 0.7452219090403807.\n",
      "[I 2024-03-20 13:25:48,909] Trial 2 finished with value: 0.7581979965650995 and parameters: {'n_hidden': 423, 'n_layer': 2, 'batch_size': 4358}. Best is trial 2 with value: 0.7581979965650995.\n",
      "[I 2024-03-20 13:28:32,476] Trial 3 finished with value: 0.7516930264455015 and parameters: {'n_hidden': 33, 'n_layer': 2, 'batch_size': 2437}. Best is trial 2 with value: 0.7581979965650995.\n",
      "[I 2024-03-20 13:30:55,307] Trial 4 finished with value: 0.7492392833563173 and parameters: {'n_hidden': 18, 'n_layer': 1, 'batch_size': 6119}. Best is trial 2 with value: 0.7581979965650995.\n",
      "[I 2024-03-20 13:37:41,904] Trial 5 finished with value: 0.7361238298383871 and parameters: {'n_hidden': 255, 'n_layer': 3, 'batch_size': 8258}. Best is trial 2 with value: 0.7581979965650995.\n",
      "[I 2024-03-20 13:41:04,460] Trial 6 finished with value: 0.7509925472865729 and parameters: {'n_hidden': 218, 'n_layer': 1, 'batch_size': 4373}. Best is trial 2 with value: 0.7581979965650995.\n",
      "[I 2024-03-20 13:48:46,953] Trial 7 finished with value: 0.7400116946679187 and parameters: {'n_hidden': 257, 'n_layer': 2, 'batch_size': 108}. Best is trial 2 with value: 0.7581979965650995.\n",
      "[I 2024-03-20 13:56:44,577] Trial 8 finished with value: 0.7229113999414094 and parameters: {'n_hidden': 465, 'n_layer': 4, 'batch_size': 5400}. Best is trial 2 with value: 0.7581979965650995.\n",
      "[I 2024-03-20 14:05:07,736] Trial 9 finished with value: 0.7449890094420026 and parameters: {'n_hidden': 304, 'n_layer': 4, 'batch_size': 487}. Best is trial 2 with value: 0.7581979965650995.\n",
      "[I 2024-03-20 14:12:00,477] Trial 10 finished with value: 0.7395281581821753 and parameters: {'n_hidden': 385, 'n_layer': 2, 'batch_size': 7186}. Best is trial 2 with value: 0.7581979965650995.\n",
      "[I 2024-03-20 14:16:44,241] Trial 11 finished with value: 0.757923466679559 and parameters: {'n_hidden': 10, 'n_layer': 2, 'batch_size': 2728}. Best is trial 2 with value: 0.7581979965650995.\n",
      "[I 2024-03-20 14:20:00,849] Trial 12 finished with value: 0.7395360094759291 and parameters: {'n_hidden': 123, 'n_layer': 2, 'batch_size': 3144}. Best is trial 2 with value: 0.7581979965650995.\n",
      "[I 2024-03-20 14:23:03,248] Trial 13 finished with value: 0.7473016135462875 and parameters: {'n_hidden': 354, 'n_layer': 1, 'batch_size': 1855}. Best is trial 2 with value: 0.7581979965650995.\n",
      "[I 2024-03-20 14:37:58,550] Trial 14 finished with value: 0.7333690873141568 and parameters: {'n_hidden': 509, 'n_layer': 3, 'batch_size': 1480}. Best is trial 2 with value: 0.7581979965650995.\n",
      "[W 2024-03-20 14:42:48,823] Trial 15 failed with parameters: {'n_hidden': 126, 'n_layer': 2, 'batch_size': 3594} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ap43owus/anaconda3/envs/tl4pm/lib/python3.8/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_71059/3560583408.py\", line 12, in objective\n",
      "    model, train_loss_source, val_loss_srouce = Trainer.train_model(model, optimizer,\n",
      "  File \"/home/ap43owus/Projects/ECIS24-TL4PM/src/trainer/Trainer.py\", line 85, in train_model\n",
      "    loss_train, sample_num_train = train_model_epoch(model, training_set, batch_size=batch_size, optimizer=optimizer,\n",
      "  File \"/home/ap43owus/Projects/ECIS24-TL4PM/src/trainer/Trainer.py\", line 68, in train_model_epoch\n",
      "    loss_prefix = forward_model_batch(model, x, y, optimizer, criterion, loss_prefix,\n",
      "  File \"/home/ap43owus/Projects/ECIS24-TL4PM/src/trainer/Trainer.py\", line 37, in forward_model_batch\n",
      "    loss_prefix = loss_prefix + loss.item()*x.shape[0]\n",
      "KeyboardInterrupt\n",
      "[W 2024-03-20 14:42:48,824] Trial 15 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m joblib\u001b[38;5;241m.\u001b[39mdump(study, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../Model/Optuna/641620split/LSTM/Study_source_641620split_st.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/tl4pm/lib/python3.8/site-packages/optuna/study/study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tl4pm/lib/python3.8/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/tl4pm/lib/python3.8/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/anaconda3/envs/tl4pm/lib/python3.8/site-packages/optuna/study/_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    247\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    250\u001b[0m ):\n\u001b[0;32m--> 251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/anaconda3/envs/tl4pm/lib/python3.8/site-packages/optuna/study/_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[25], line 12\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     10\u001b[0m model \u001b[38;5;241m=\u001b[39m DLModels\u001b[38;5;241m.\u001b[39mSimpleLSTM(input_size, hidden_size, num_layers, num_classes)\u001b[38;5;241m.\u001b[39mto(torch_device)\n\u001b[1;32m     11\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlearning_rate)\n\u001b[0;32m---> 12\u001b[0m model, train_loss_source, val_loss_srouce \u001b[38;5;241m=\u001b[39m \u001b[43mTrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                                                               \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                                                               \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                                                               \u001b[49m\u001b[43mval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                                                               \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                                                               \u001b[49m\u001b[43mtorch_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                                                               \u001b[49m\u001b[43mdevice_package\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m                                                               \u001b[49m\u001b[43mTrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprefix_weighted_loss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m                                                               \u001b[49m\u001b[43mtrainer_hyper_para\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_epoch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m                                                               \u001b[49m\u001b[43mtrainer_hyper_para\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_ob_iter\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m                                                               \u001b[49m\u001b[43mtrainer_hyper_para\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore_margin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m                                                               \u001b[49m\u001b[43mprint_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m model\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m     27\u001b[0m roc_auc, f1, f1_inverse, precision, precision_inverse, recall, recall_inverse \u001b[38;5;241m=\u001b[39m Trainer\u001b[38;5;241m.\u001b[39meval_model(model, val_set,\n\u001b[1;32m     28\u001b[0m                                                                                                        torch_device\u001b[38;5;241m=\u001b[39mtorch_device,\n\u001b[1;32m     29\u001b[0m                                                                                                        device_package\u001b[38;5;241m=\u001b[39mdevice_package)\n",
      "File \u001b[0;32m~/Projects/ECIS24-TL4PM/src/trainer/Trainer.py:85\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, optimizer, criterion, criterion_eval, training_set, val_set, batch_size, torch_device, device_package, eval_func, max_epoch, max_ob_iter, score_margin, print_iter)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m iter_epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_epoch):\n\u001b[1;32m     84\u001b[0m     device_package\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[0;32m---> 85\u001b[0m     loss_train, sample_num_train \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch_device\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_device\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m     device_package\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[1;32m     88\u001b[0m     loss_val, sample_num_val \u001b[38;5;241m=\u001b[39m train_model_epoch(model, val_set, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[1;32m     89\u001b[0m                                                  criterion\u001b[38;5;241m=\u001b[39mcriterion_eval, torch_device\u001b[38;5;241m=\u001b[39mtorch_device, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Projects/ECIS24-TL4PM/src/trainer/Trainer.py:68\u001b[0m, in \u001b[0;36mtrain_model_epoch\u001b[0;34m(model, training_set, optimizer, criterion, torch_device, batch_size, training)\u001b[0m\n\u001b[1;32m     66\u001b[0m         x \u001b[38;5;241m=\u001b[39m input_data[\u001b[38;5;241m0\u001b[39m][batch_size \u001b[38;5;241m*\u001b[39m batch_num :]\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(torch_device)\n\u001b[1;32m     67\u001b[0m         y \u001b[38;5;241m=\u001b[39m input_data[\u001b[38;5;241m1\u001b[39m][batch_size \u001b[38;5;241m*\u001b[39m batch_num :]\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(torch_device)\n\u001b[0;32m---> 68\u001b[0m         loss_prefix \u001b[38;5;241m=\u001b[39m \u001b[43mforward_model_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mtorch_device\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m     loss_prefix_list\u001b[38;5;241m.\u001b[39mappend(loss_prefix)\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(loss_prefix_list), np\u001b[38;5;241m.\u001b[39marray(sample_num_list)\n",
      "File \u001b[0;32m~/Projects/ECIS24-TL4PM/src/trainer/Trainer.py:37\u001b[0m, in \u001b[0;36mforward_model_batch\u001b[0;34m(model, x, y, optimizer, criterion, loss_prefix, torch_device, training)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     36\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, y)\n\u001b[0;32m---> 37\u001b[0m loss_prefix \u001b[38;5;241m=\u001b[39m loss_prefix \u001b[38;5;241m+\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m*\u001b[39mx\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss_prefix\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=50)\n",
    "joblib.dump(study, \"../../Model/Optuna/641620split/LSTM/Study_source_641620split_st.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e06dca71-ab96-4262-949c-15f9c1a8d0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = joblib.load(\"../../Model/Optuna/641620split/LSTM/Study_source.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1fabdee0-279d-4395-a54b-e443d12a0c65",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Study' object has no attribute 'StudySummary'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStudySummary\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Study' object has no attribute 'StudySummary'"
     ]
    }
   ],
   "source": [
    "study.StudySummary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
