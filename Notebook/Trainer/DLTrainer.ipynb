{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dccafe7e-273e-4a0d-9297-45e4e520db0a",
   "metadata": {},
   "source": [
    "# Deep learning model trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d695b248-f088-4220-bdd3-f308bb6f99fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import pickle as pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from src.trainer import CaseDataSet\n",
    "from src.model import DLModels\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "import importlib.util\n",
    "torch_device = \"cpu\"\n",
    "device_package = torch.cpu\n",
    "if importlib.util.find_spec(\"torch.backends.mps\") is not None:\n",
    "    if torch.backends.mps.is_available():\n",
    "        torch_device = torch.device(\"mps\")\n",
    "        device_package = torch.mps\n",
    "if torch.cuda.is_available():\n",
    "    torch_device = torch.device(\"cuda\")\n",
    "    device_package = torch.cuda\n",
    "    \n",
    "torch_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f60d30e-a0fd-4609-9c8b-ce85ff15530c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prefix_weighted_loss(loss_list, sample_num):\n",
    "    return np.sum(loss_list * sample_num) / np.sum(sample_num)\n",
    "\n",
    "def BCE_counter_imblance(y):\n",
    "    class_weight = 1\n",
    "    if (1-y).sum() * y.sum() > 0:\n",
    "        class_weight = ((1-y).sum()/y.sum())\n",
    "    pos_weight = torch.ones(1).to(torch_device) * class_weight\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "    return criterion\n",
    "\n",
    "\n",
    "def forward_model_batch(model, x, y, optimizer, criterion, loss_prefix, training=True):\n",
    "    if criterion is None:\n",
    "        criterion = BCE_counter_imblance(y)\n",
    "    outputs = model(x)\n",
    "    # Backward and optimize\n",
    "    if training:\n",
    "        loss = criterion(outputs, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    else:\n",
    "        loss = criterion(outputs, y)\n",
    "    loss_prefix = loss_prefix + loss.item()*x.shape[0]\n",
    "    return loss_prefix\n",
    "    \n",
    "    \n",
    "def train_model_epoch(model, training_set, optimizer, criterion, torch_device, batch_size=50, training=True):\n",
    "    training_data_set = training_set\n",
    "    batch_size = batch_size\n",
    "    loss_prefix_list = []\n",
    "    sample_num_list = []\n",
    "    for prefix_len in range(1, training_data_set.max_case_len):\n",
    "        loss_prefix = 0\n",
    "        training_data_set.set_prefix_length(prefix_len)\n",
    "        training_data_set.shuffle_data()\n",
    "        input_data = training_data_set[:]\n",
    "        if input_data is None:\n",
    "            # print(\"Max length reached, abort\")\n",
    "            break\n",
    "        sample_num = input_data[0].shape[0]\n",
    "        # print(\"Starting training at prefix length: \", prefix_len, \" with sample num: \", sample_num)\n",
    "        sample_num_list.append(sample_num)\n",
    "\n",
    "        batch_num = int(sample_num / batch_size)\n",
    "        for i in range(batch_num):\n",
    "            x = input_data[0][int(batch_size * i) : int(batch_size * (i+1))].float().to(torch_device)\n",
    "            y = input_data[1][int(batch_size * i) : int(batch_size * (i+1))].float().to(torch_device)\n",
    "            loss_prefix = forward_model_batch(model, x, y, optimizer, criterion, loss_prefix, training=True)\n",
    "\n",
    "        if sample_num > batch_size * batch_num:\n",
    "            x = input_data[0][batch_size * batch_num :].float().to(torch_device)\n",
    "            y = input_data[1][batch_size * batch_num :].float().to(torch_device)\n",
    "            loss_prefix = forward_model_batch(model, x, y, optimizer, criterion, loss_prefix, training=True)\n",
    "\n",
    "        loss_prefix_list.append(loss_prefix)\n",
    "    return np.array(loss_prefix_list), np.array(sample_num_list)   \n",
    "\n",
    "\n",
    "def train_model(model, optimizer, criterion, criterion_eval, training_set, val_set,\n",
    "                batch_size, torch_device, device_package, eval_func=prefix_weighted_loss,\n",
    "                max_epoch=100, max_ob_iter=20, score_margin=1e-4, print_iter=False):\n",
    "    train_loss_list = []\n",
    "    val_loss_list = []\n",
    "    score = 1e5\n",
    "    best_iter = 0\n",
    "    best_model = None\n",
    "    for iter_epoch in range(max_epoch):\n",
    "        device_package.empty_cache()\n",
    "        loss_train, sample_num_train = train_model_epoch(model, training_set, batch_size=batch_size, optimizer=optimizer,\n",
    "                                                         criterion=criterion, torch_device=torch_device)\n",
    "        device_package.empty_cache()\n",
    "        loss_val, sample_num_val = train_model_epoch(model, val_set, batch_size=batch_size, optimizer=optimizer,\n",
    "                                                     criterion=criterion_eval, torch_device=torch_device, training=False)\n",
    "\n",
    "        score_train = eval_func(loss_train, sample_num_train)\n",
    "        score_val = eval_func(loss_val, sample_num_val)\n",
    "        train_loss_list.append(score_train)\n",
    "        val_loss_list.append(score_val)\n",
    "\n",
    "        if score_val < (score - score_margin):\n",
    "            score = score_val\n",
    "            best_model = copy.deepcopy(model)\n",
    "            best_iter = iter_epoch\n",
    "\n",
    "        if iter_epoch > best_iter + max_ob_iter:\n",
    "            break\n",
    "        if print_iter:\n",
    "            print(\"Finished training iteration: \", iter_epoch, \" with val loss: \", score_val, \" train loss: \", score_train)\n",
    "    device_package.empty_cache()\n",
    "    return best_model, np.array(train_loss_list), np.array(val_loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1512b7c6-95f2-4bab-8757-97c7215a9400",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_set, torch_device, device_package):\n",
    "    res_list = []\n",
    "    ref_list = []\n",
    "    sample_num_list = []\n",
    "    device_package.empty_cache()\n",
    "    for prefix_len in range(1, test_set.max_case_len):\n",
    "        test_set.set_prefix_length(prefix_len)\n",
    "        input_data = test_set[:]\n",
    "        if input_data is None:\n",
    "            # print(\"Max length reached, abort\")\n",
    "            break\n",
    "        sample_num = input_data[0].shape[0]\n",
    "        sample_num_list.append(sample_num)\n",
    "        x = input_data[0].float().to(torch_device)\n",
    "        y = input_data[1].float().to(torch_device)\n",
    "        ref_list.append(y.cpu())\n",
    "        outputs = model(x)\n",
    "        prob = torch.sigmoid(outputs).detach().cpu()\n",
    "        res_list.append(prob)\n",
    "        \n",
    "    device_package.empty_cache()\n",
    "    return res_list, ref_list, sample_num_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59728e6-6ae1-441e-b53d-31c728919f06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cd9b716-208d-4a74-b088-f6b155e8a28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_train = CaseDataSet.CaseDataset(split_pattern=\"641620split\", input_data=\"source\", data_version=\"_train_random_all\",\n",
    "                                       embedding_version=\"_w2v\", earliness_requirement=True)\n",
    "source_val = CaseDataSet.CaseDataset(split_pattern=\"641620split\", input_data=\"source\", data_version=\"_val_random_all\",\n",
    "                                       embedding_version=\"_w2v\", earliness_requirement=True)\n",
    "source_test = CaseDataSet.CaseDataset(split_pattern=\"641620split\", input_data=\"source\", data_version=\"_test_random_all\",\n",
    "                                       embedding_version=\"_w2v\", earliness_requirement=True)\n",
    "target_test = CaseDataSet.CaseDataset(split_pattern=\"641620split\", input_data=\"target\", data_version=\"_test_random_all\",\n",
    "                                       embedding_version=\"_w2v\", earliness_requirement=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fba531d5-4a8a-47aa-9ab5-2ec850c63c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "input_size = 51  # The number of expected features in the input x\n",
    "hidden_size = 128  # The number of features in the hidden state h\n",
    "num_layers = 1  # Number of recurrent layers\n",
    "num_classes = 1  # For binary classification\n",
    "learning_rate = 0.001\n",
    "batch_size = 1000\n",
    "\n",
    "# Instantiate the model\n",
    "model = DLModels.SimpleLSTM(input_size, hidden_size, num_layers, num_classes).to(torch_device)\n",
    "# model = TransformerEncoderModel(43, 64, 8, 12, True).to(torch_device)\n",
    "# Define the loss and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5b98ace-d84f-44e5-bad6-8f10c0895e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training iteration:  0  with val loss:  1454.1883904547942  train loss:  2663.568985870707\n",
      "Finished training iteration:  1  with val loss:  1165.9653913483737  train loss:  2547.429804242685\n",
      "Finished training iteration:  2  with val loss:  1298.7271898505048  train loss:  2661.9006989695536\n",
      "Finished training iteration:  3  with val loss:  1183.2093943849352  train loss:  2807.2031783791126\n",
      "Finished training iteration:  4  with val loss:  1375.2468248252094  train loss:  2730.1771333482816\n",
      "Finished training iteration:  5  with val loss:  1286.4815297279433  train loss:  2781.6547341560045\n",
      "Finished training iteration:  6  with val loss:  1300.7628156539072  train loss:  2760.6526457973646\n",
      "Finished training iteration:  7  with val loss:  1458.2020619033835  train loss:  2747.6933279300806\n",
      "Finished training iteration:  8  with val loss:  1418.5225154881746  train loss:  2653.8402600322347\n",
      "Finished training iteration:  9  with val loss:  1350.0336661204046  train loss:  2763.3535451961743\n",
      "Finished training iteration:  10  with val loss:  1264.5887876276793  train loss:  2584.6438066681917\n",
      "Finished training iteration:  11  with val loss:  1124.1348079597103  train loss:  2685.238816970784\n",
      "Finished training iteration:  12  with val loss:  1169.2490149504997  train loss:  2603.498871779562\n",
      "Finished training iteration:  13  with val loss:  1239.959222481529  train loss:  2573.2084650618494\n",
      "Finished training iteration:  14  with val loss:  1267.0463687583826  train loss:  2680.2514403300875\n",
      "Finished training iteration:  15  with val loss:  1222.7208570089751  train loss:  2720.16459453758\n",
      "Finished training iteration:  16  with val loss:  1306.8640093160716  train loss:  2724.9684506105523\n",
      "Finished training iteration:  17  with val loss:  1250.712983229867  train loss:  2582.285729569657\n",
      "Finished training iteration:  18  with val loss:  1233.1472424865617  train loss:  2716.5377513799476\n",
      "Finished training iteration:  19  with val loss:  1404.5906133543  train loss:  2638.3079065623197\n",
      "Finished training iteration:  20  with val loss:  1334.3957998090798  train loss:  2622.135892834251\n",
      "Finished training iteration:  21  with val loss:  1363.3250868607513  train loss:  2584.934143536699\n",
      "Finished training iteration:  22  with val loss:  1314.1607522753757  train loss:  2655.858667759337\n",
      "Finished training iteration:  23  with val loss:  1229.6690979608263  train loss:  2600.6883854038233\n",
      "Finished training iteration:  24  with val loss:  1293.3238832655168  train loss:  2572.9061748108143\n",
      "Finished training iteration:  25  with val loss:  1277.4347224573157  train loss:  2615.4803561467634\n",
      "Finished training iteration:  26  with val loss:  1252.9507318455221  train loss:  2706.257918877626\n",
      "Finished training iteration:  27  with val loss:  1251.7798654597368  train loss:  2619.2872046020975\n",
      "Finished training iteration:  28  with val loss:  1241.7667383525093  train loss:  2600.8289560088124\n",
      "Finished training iteration:  29  with val loss:  1227.2736383659908  train loss:  2543.4626112008486\n",
      "Finished training iteration:  30  with val loss:  1254.1107887149908  train loss:  2570.2634356405556\n",
      "Finished training iteration:  31  with val loss:  1335.8776502645517  train loss:  2534.5493771756132\n"
     ]
    }
   ],
   "source": [
    "model, train_loss, val_loss = train_model(model, optimizer, None, None, source_train, source_val, batch_size,\n",
    "                                          torch_device, device_package, eval_func=prefix_weighted_loss,\n",
    "                                          max_epoch=50, max_ob_iter=20, score_margin=1e-4, print_iter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e24c7f6-7712-4c22-8a21-c060471643c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc:  0.7885650802533464\n",
      "roc_auc inverse:  0.7885650802533464\n",
      "f1:  0.8829895112833165\n",
      "f1 inverse:  0.49274981956564534\n",
      "Precision:  0.8473985416727188\n",
      "Precision inverse:  0.602438633081983\n",
      "Recall:  0.921701213346815\n",
      "Recall inverse:  0.4168516873889876\n"
     ]
    }
   ],
   "source": [
    "model.flatten()\n",
    "res, ref, num = evaluate_model(model, source_test, torch_device, device_package)\n",
    "res_p = np.squeeze(torch.concat(res).numpy())\n",
    "res_c = copy.copy(res_p)\n",
    "res_c[res_c < 0.5] = 0\n",
    "res_c[res_c >= 0.5] = 1\n",
    "ref_p = np.squeeze(torch.concat(ref).numpy()).astype(int)\n",
    "print(\"roc_auc: \", roc_auc_score(ref_p, res_p))\n",
    "print(\"roc_auc inverse: \", roc_auc_score(1-ref_p, 1-res_p))\n",
    "print(\"f1: \", f1_score(ref_p, res_c))\n",
    "print(\"f1 inverse: \", f1_score(1-ref_p, 1-res_c))\n",
    "print(\"Precision: \", precision_score(ref_p, res_c))\n",
    "print(\"Precision inverse: \", precision_score(1-ref_p, 1-res_c))\n",
    "print(\"Recall: \", recall_score(ref_p, res_c))\n",
    "print(\"Recall inverse: \", recall_score(1-ref_p, 1-res_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0277d920-ae6e-4725-a46f-459dbe10e12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc:  0.5657107246633903\n",
      "roc_auc inverse:  0.5657108244902032\n",
      "f1:  0.7263002197052436\n",
      "f1 inverse:  0.3176587817896788\n",
      "Precision:  0.7081897707301089\n",
      "Precision inverse:  0.3392898301178193\n",
      "Recall:  0.7453612503069856\n",
      "Recall inverse:  0.29862055798190973\n"
     ]
    }
   ],
   "source": [
    "model.flatten()\n",
    "res, ref, num = evaluate_model(model, target_test, torch_device, device_package)\n",
    "res_p = np.squeeze(torch.concat(res).numpy())\n",
    "res_c = copy.copy(res_p)\n",
    "res_c[res_c < 0.5] = 0\n",
    "res_c[res_c >= 0.5] = 1\n",
    "ref_p = np.squeeze(torch.concat(ref).numpy()).astype(int)\n",
    "print(\"roc_auc: \", roc_auc_score(ref_p, res_p))\n",
    "print(\"roc_auc inverse: \", roc_auc_score(1-ref_p, 1-res_p))\n",
    "print(\"f1: \", f1_score(ref_p, res_c))\n",
    "print(\"f1 inverse: \", f1_score(1-ref_p, 1-res_c))\n",
    "print(\"Precision: \", precision_score(ref_p, res_c))\n",
    "print(\"Precision inverse: \", precision_score(1-ref_p, 1-res_c))\n",
    "print(\"Recall: \", recall_score(ref_p, res_c))\n",
    "print(\"Recall inverse: \", recall_score(1-ref_p, 1-res_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b6e1c16-efdf-4369-a513-37f7f9913b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_train_st = CaseDataSet.CaseDataset(split_pattern=\"641620split\", input_data=\"source\", data_version=\"_train\",\n",
    "                                       embedding_version=\"_st\", time_feature=False, earliness_requirement=True)\n",
    "source_val_st = CaseDataSet.CaseDataset(split_pattern=\"641620split\", input_data=\"source\", data_version=\"_val\",\n",
    "                                       embedding_version=\"_st\", time_feature=False, earliness_requirement=True)\n",
    "source_test_st = CaseDataSet.CaseDataset(split_pattern=\"641620split\", input_data=\"source\", data_version=\"_test\",\n",
    "                                       embedding_version=\"_st\", time_feature=False, earliness_requirement=True)\n",
    "target_test_st = CaseDataSet.CaseDataset(split_pattern=\"641620split\", input_data=\"target\", data_version=\"_test\",\n",
    "                                       embedding_version=\"_st\", time_feature=False, earliness_requirement=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10a4c376-e1e1-4164-ae39-19cf24993669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training iteration:  0  with val loss:  994.882828364117  train loss:  1988.270744518225\n",
      "Finished training iteration:  1  with val loss:  1009.9968720959209  train loss:  2012.4854504956372\n",
      "Finished training iteration:  2  with val loss:  1126.104799346354  train loss:  2105.8544062760798\n",
      "Finished training iteration:  3  with val loss:  986.4861330248463  train loss:  2062.4674202035994\n",
      "Finished training iteration:  4  with val loss:  1007.3421818100113  train loss:  2116.763931458579\n",
      "Finished training iteration:  5  with val loss:  992.2425909738512  train loss:  2138.943605089617\n",
      "Finished training iteration:  6  with val loss:  955.7647128416767  train loss:  2050.9211195979947\n",
      "Finished training iteration:  7  with val loss:  942.04925483356  train loss:  2017.2175402620571\n",
      "Finished training iteration:  8  with val loss:  973.3445737172824  train loss:  2056.1870024174227\n",
      "Finished training iteration:  9  with val loss:  955.067083382819  train loss:  2162.64045098369\n",
      "Finished training iteration:  10  with val loss:  1041.5823952895773  train loss:  2012.5544661160334\n",
      "Finished training iteration:  11  with val loss:  1037.6632423555914  train loss:  1996.4804049389782\n",
      "Finished training iteration:  12  with val loss:  981.6020771661518  train loss:  2100.3761032888365\n",
      "Finished training iteration:  13  with val loss:  1022.4886710484611  train loss:  2039.343666161412\n",
      "Finished training iteration:  14  with val loss:  986.7922278914524  train loss:  2093.4960222639406\n",
      "Finished training iteration:  15  with val loss:  1022.3958996017169  train loss:  2036.3728246460719\n",
      "Finished training iteration:  16  with val loss:  976.7439789151089  train loss:  2010.6141660391788\n",
      "Finished training iteration:  17  with val loss:  995.5658244670657  train loss:  2034.8264141653683\n",
      "Finished training iteration:  18  with val loss:  1046.235067477376  train loss:  2022.0974554370991\n",
      "Finished training iteration:  19  with val loss:  1057.312173395326  train loss:  2170.571043995649\n",
      "Finished training iteration:  20  with val loss:  1234.1595798724466  train loss:  2056.951764126146\n",
      "Finished training iteration:  21  with val loss:  1005.07191931368  train loss:  2062.178577821744\n",
      "Finished training iteration:  22  with val loss:  961.400631767404  train loss:  2100.3669468215835\n",
      "Finished training iteration:  23  with val loss:  1006.1075854791762  train loss:  2081.112564143693\n",
      "Finished training iteration:  24  with val loss:  1039.979146888859  train loss:  1960.3779733870688\n",
      "Finished training iteration:  25  with val loss:  1004.7578376286098  train loss:  2060.2108520388942\n",
      "Finished training iteration:  26  with val loss:  986.1118401381594  train loss:  2068.3733021043167\n",
      "Finished training iteration:  27  with val loss:  1106.06591879331  train loss:  2013.6179883659163\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "input_size = 384  # The number of expected features in the input x\n",
    "hidden_size = 512  # The number of features in the hidden state h\n",
    "num_layers = 1  # Number of recurrent layers\n",
    "num_classes = 1  # For binary classification\n",
    "learning_rate = 0.001\n",
    "batch_size = 1000\n",
    "\n",
    "# Instantiate the model\n",
    "model = DLModels.SimpleLSTM(input_size, hidden_size, num_layers, num_classes).to(torch_device)\n",
    "# model = TransformerEncoderModel(43, 64, 8, 12, True).to(torch_device)\n",
    "# Define the loss and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "model, train_loss, val_loss = train_model(model, optimizer, None, None, source_train_st, source_val_st, batch_size,\n",
    "                                          torch_device, device_package, eval_func=prefix_weighted_loss,\n",
    "                                          max_epoch=100, max_ob_iter=20, score_margin=1, print_iter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5f1135a-8802-44cf-8227-eee1efbf44b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc:  0.6996676141731326\n",
      "f1:  0.866321506040311\n",
      "f1 inverse:  0.1733085283462254\n",
      "Precision:  0.7764659136061759\n",
      "Precision inverse:  0.609504132231405\n",
      "Recall:  0.9796956132497762\n",
      "Recall inverse:  0.10101586576874785\n"
     ]
    }
   ],
   "source": [
    "model.flatten()\n",
    "res, ref, num = evaluate_model(model, source_test_st, torch_device, device_package)\n",
    "res_p = np.squeeze(torch.concat(res).numpy())\n",
    "res_c = copy.copy(res_p)\n",
    "res_c[res_c < 0.5] = 0\n",
    "res_c[res_c >= 0.5] = 1\n",
    "ref_p = np.squeeze(torch.concat(ref).numpy()).astype(int)\n",
    "print(\"roc_auc: \", roc_auc_score(ref_p, res_p))\n",
    "print(\"f1: \", f1_score(ref_p, res_c))\n",
    "print(\"f1 inverse: \", f1_score(1-ref_p, 1-res_c))\n",
    "print(\"Precision: \", precision_score(ref_p, res_c))\n",
    "print(\"Precision inverse: \", precision_score(1-ref_p, 1-res_c))\n",
    "print(\"Recall: \", recall_score(ref_p, res_c))\n",
    "print(\"Recall inverse: \", recall_score(1-ref_p, 1-res_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03da6d81-1b1b-4195-bbdb-b03924c86258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc:  0.4622537910723212\n",
      "f1:  0.8357323795131602\n",
      "f1 inverse:  0.015988277434060567\n",
      "Precision:  0.7243315822948811\n",
      "Precision inverse:  0.20314439387670666\n",
      "Recall:  0.9876275944471924\n",
      "Recall inverse:  0.008321610765554294\n"
     ]
    }
   ],
   "source": [
    "model.flatten()\n",
    "res, ref, num = evaluate_model(model, target_test_st, torch_device, device_package)\n",
    "res_p = np.squeeze(torch.concat(res).numpy())\n",
    "res_c = copy.copy(res_p)\n",
    "res_c[res_c < 0.5] = 0\n",
    "res_c[res_c >= 0.5] = 1\n",
    "ref_p = np.squeeze(torch.concat(ref).numpy()).astype(int)\n",
    "print(\"roc_auc: \", roc_auc_score(ref_p, res_p))\n",
    "print(\"f1: \", f1_score(ref_p, res_c))\n",
    "print(\"f1 inverse: \", f1_score(1-ref_p, 1-res_c))\n",
    "print(\"Precision: \", precision_score(ref_p, res_c))\n",
    "print(\"Precision inverse: \", precision_score(1-ref_p, 1-res_c))\n",
    "print(\"Recall: \", recall_score(ref_p, res_c))\n",
    "print(\"Recall inverse: \", recall_score(1-ref_p, 1-res_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6c2bf06e-b9f4-4962-ba7f-2c8153b075b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7199,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_c[res_c == 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "88a9e727-cdc8-4fb0-8e74-debb25e7e036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59003,)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_p[ref_p == 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8d536011-2b60-418a-bbbf-276b853f2aa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(275179,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_c.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
