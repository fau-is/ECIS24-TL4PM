{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cf36ca1-1491-41a6-b808-ed0c9a99eb2f",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df86cfd8-e025-4099-a61e-3c2ba8f04cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import pickle as pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from src.trainer import CaseDataSet\n",
    "from src.model import DLModels\n",
    "from src.trainer import Trainer\n",
    "from src.utils import TorchUtils\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d415bd6-9161-4e16-9b9c-b4ba621cbc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, test_set, torch_device, device_package, decision_boundary=0.5,\n",
    "               weighted=True, print_res=False):\n",
    "    model.flatten()\n",
    "    res, ref, num = Trainer.evaluate_model(model, test_set, torch_device, device_package)\n",
    "    res_prob = np.squeeze(torch.concat(res).numpy())\n",
    "    res_class = copy.copy(res_prob)\n",
    "    res_class[res_class < decision_boundary] = 0\n",
    "    res_class[res_class >= decision_boundary] = 1\n",
    "    ref_class = np.squeeze(torch.concat(ref).numpy()).astype(int)\n",
    "    roc_auc = roc_auc_score(ref_class, res_prob)\n",
    "    f1 = f1_score(ref_class, res_class)\n",
    "    f1_inverse = f1_score(1-ref_class, 1-res_class)\n",
    "    precision = precision_score(ref_class, res_class)\n",
    "    precision_inverse = precision_score(1-ref_class, 1-res_class)\n",
    "    recall = recall_score(ref_class, res_class)\n",
    "    recall_inverse = recall_score(1-ref_class, 1-res_class)\n",
    "    if print_res:\n",
    "        print(\"roc_auc: \", roc_auc)\n",
    "        print(\"f1: \", f1)\n",
    "        print(\"f1 inverse: \", f1_inverse)\n",
    "        print(\"Precision: \", precision)\n",
    "        print(\"Precision inverse: \", precision_inverse)\n",
    "        print(\"Recall: \", recall)\n",
    "        print(\"Recall inverse: \", recall_inverse)\n",
    "\n",
    "    if weighted:\n",
    "        total_class_num = ref_class.shape[0]\n",
    "        pos_class_num = ref_class.sum()\n",
    "        neg_class_num = total_class_num - ref_class.sum()\n",
    "        weighted_f1 = (f1*pos_class_num + f1_inverse*neg_class_num) / total_class_num\n",
    "        weighted_precision = (precision*pos_class_num + precision_inverse*neg_class_num) / total_class_num\n",
    "        weighted_recall = (recall*pos_class_num + recall_inverse*neg_class_num) / total_class_num\n",
    "        print(\"roc_auc: \", roc_auc)\n",
    "        print(\"weighted f1: \", weighted_f1)\n",
    "        print(\"weighted_precision: \", weighted_precision)\n",
    "        print(\"weighted_recall: \", weighted_recall)\n",
    "        return [roc_auc, weighted_f1, weighted_precision, weighted_recall]\n",
    "    else:\n",
    "        return [roc_auc, f1, f1_inverse, precision, precision_inverse, recall, recall_inverse]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "5876df89-c1fe-4bb6-81d4-c58e358f1e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_test_set = CaseDataSet.CaseDataset(split_pattern=\"641620split\", input_data=\"target\",\n",
    "                                  data_version=\"_test_sorted\", embedding_version=\"_st\",\n",
    "                                  earliness_requirement=True)\n",
    "source_test_set = CaseDataSet.CaseDataset(split_pattern=\"641620split\", input_data=\"source\",\n",
    "                                  data_version=\"_test_sorted\", embedding_version=\"_st\",\n",
    "                                  earliness_requirement=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "0a55f5bd-64c0-4a1d-b188-392b9fd86792",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"../../Model/641620split/LSTM/LSTM_T_h512_l1_st_b3.LSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "17a257b3-5d2b-4c4a-a050-99f502c872cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_test_set = CaseDataSet.CaseDataset(split_pattern=\"641620split\", input_data=\"target\",\n",
    "                                  data_version=\"_test_sorted\", embedding_version=\"_st\",\n",
    "                                  earliness_requirement=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "61ad1ecd-56b4-46f5-b942-36f05118b903",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"../../Model/scale/LSTM/LSTM_T_h512_l1_st_0.01_.LSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0b02de-201d-40be-834c-ce4c884c1da6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "760505bf-92b3-473e-afe4-8d28b971feff",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "input.size(-1) must be equal to input_size. Expected 48, got 385",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[186], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m torch_device, device_package \u001b[38;5;241m=\u001b[39m TorchUtils\u001b[38;5;241m.\u001b[39mget_torch_device()\n\u001b[0;32m----> 2\u001b[0m \u001b[43meval_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource_test_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m           \u001b[49m\u001b[43mdevice_package\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecision_boundary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m           \u001b[49m\u001b[43mweighted\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_res\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[32], line 4\u001b[0m, in \u001b[0;36meval_model\u001b[0;34m(model, test_set, torch_device, device_package, decision_boundary, weighted, print_res)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21meval_model\u001b[39m(model, test_set, torch_device, device_package, decision_boundary\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m,\n\u001b[1;32m      2\u001b[0m                weighted\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, print_res\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m      3\u001b[0m     model\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m----> 4\u001b[0m     res, ref, num \u001b[38;5;241m=\u001b[39m \u001b[43mTrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch_device\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_package\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     res_prob \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqueeze(torch\u001b[38;5;241m.\u001b[39mconcat(res)\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m      6\u001b[0m     res_class \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mcopy(res_prob)\n",
      "File \u001b[0;32m~/Projects/ECIS24-TL4PM/src/trainer/Trainer.py:125\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(model, test_set, torch_device, device_package)\u001b[0m\n\u001b[1;32m    123\u001b[0m y = input_data[1].float().to(torch_device)\n\u001b[1;32m    124\u001b[0m ref_list.append(y.cpu())\n\u001b[0;32m--> 125\u001b[0m outputs = model(x)\n\u001b[1;32m    126\u001b[0m prob = torch.sigmoid(outputs).detach().cpu()\n\u001b[1;32m    127\u001b[0m res_list.append(prob)\n",
      "File \u001b[0;32m~/anaconda3/envs/tl4pm/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Projects/ECIS24-TL4PM/src/model/DLModels.py:18\u001b[0m, in \u001b[0;36mSimpleLSTM.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     15\u001b[0m c0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size)\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Forward propagate LSTM\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m out, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mh0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc0\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# out: tensor of shape (batch_size, seq_length, hidden_size)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Only take the output from the final timetep\u001b[39;00m\n\u001b[1;32m     21\u001b[0m out \u001b[38;5;241m=\u001b[39m out[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\n",
      "File \u001b[0;32m~/anaconda3/envs/tl4pm/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/tl4pm/lib/python3.8/site-packages/torch/nn/modules/rnn.py:810\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    806\u001b[0m     \u001b[38;5;66;03m# Each batch of the hidden state should match the input sequence that\u001b[39;00m\n\u001b[1;32m    807\u001b[0m     \u001b[38;5;66;03m# the user believes he/she is passing in.\u001b[39;00m\n\u001b[1;32m    808\u001b[0m     hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[0;32m--> 810\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_forward_args\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    811\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    812\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers,\n\u001b[1;32m    813\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first)\n",
      "File \u001b[0;32m~/anaconda3/envs/tl4pm/lib/python3.8/site-packages/torch/nn/modules/rnn.py:730\u001b[0m, in \u001b[0;36mLSTM.check_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    725\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_forward_args\u001b[39m(\u001b[38;5;28mself\u001b[39m,  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[1;32m    726\u001b[0m                        \u001b[38;5;28minput\u001b[39m: Tensor,\n\u001b[1;32m    727\u001b[0m                        hidden: Tuple[Tensor, Tensor],\n\u001b[1;32m    728\u001b[0m                        batch_sizes: Optional[Tensor],\n\u001b[1;32m    729\u001b[0m                        ):\n\u001b[0;32m--> 730\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_hidden_size(hidden[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_expected_hidden_size(\u001b[38;5;28minput\u001b[39m, batch_sizes),\n\u001b[1;32m    732\u001b[0m                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected hidden[0] size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    733\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_hidden_size(hidden[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_expected_cell_size(\u001b[38;5;28minput\u001b[39m, batch_sizes),\n\u001b[1;32m    734\u001b[0m                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected hidden[1] size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/tl4pm/lib/python3.8/site-packages/torch/nn/modules/rnn.py:218\u001b[0m, in \u001b[0;36mRNNBase.check_input\u001b[0;34m(self, input, batch_sizes)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    215\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput must have \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m dimensions, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    216\u001b[0m             expected_input_dim, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim()))\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m--> 218\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput.size(-1) must be equal to input_size. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    220\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 48, got 385"
     ]
    }
   ],
   "source": [
    "torch_device, device_package = TorchUtils.get_torch_device()\n",
    "eval_model(model, source_test_set, torch_device,\n",
    "           device_package, decision_boundary=0.5,\n",
    "           weighted=False, print_res=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "f3cd604a-4018-45e6-a5d0-abb6b6aa60cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 514.00 MiB (GPU 0; 23.66 GiB total capacity; 1.55 GiB already allocated; 438.44 MiB free; 2.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[204], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m torch_device, device_package \u001b[38;5;241m=\u001b[39m TorchUtils\u001b[38;5;241m.\u001b[39mget_torch_device()\n\u001b[0;32m----> 2\u001b[0m \u001b[43meval_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_test_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m           \u001b[49m\u001b[43mdevice_package\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecision_boundary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m           \u001b[49m\u001b[43mweighted\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_res\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[32], line 4\u001b[0m, in \u001b[0;36meval_model\u001b[0;34m(model, test_set, torch_device, device_package, decision_boundary, weighted, print_res)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21meval_model\u001b[39m(model, test_set, torch_device, device_package, decision_boundary\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m,\n\u001b[1;32m      2\u001b[0m                weighted\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, print_res\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m      3\u001b[0m     model\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m----> 4\u001b[0m     res, ref, num \u001b[38;5;241m=\u001b[39m \u001b[43mTrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch_device\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_package\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     res_prob \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqueeze(torch\u001b[38;5;241m.\u001b[39mconcat(res)\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m      6\u001b[0m     res_class \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mcopy(res_prob)\n",
      "File \u001b[0;32m~/Projects/ECIS24-TL4PM/src/trainer/Trainer.py:125\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(model, test_set, torch_device, device_package)\u001b[0m\n\u001b[1;32m    123\u001b[0m y = input_data[1].float().to(torch_device)\n\u001b[1;32m    124\u001b[0m ref_list.append(y.cpu())\n\u001b[0;32m--> 125\u001b[0m outputs = model(x)\n\u001b[1;32m    126\u001b[0m prob = torch.sigmoid(outputs).detach().cpu()\n\u001b[1;32m    127\u001b[0m res_list.append(prob)\n",
      "File \u001b[0;32m~/anaconda3/envs/tl4pm/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Projects/ECIS24-TL4PM/src/model/DLModels.py:18\u001b[0m, in \u001b[0;36mSimpleLSTM.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     15\u001b[0m c0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size)\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Forward propagate LSTM\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m out, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mh0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc0\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# out: tensor of shape (batch_size, seq_length, hidden_size)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Only take the output from the final timetep\u001b[39;00m\n\u001b[1;32m     21\u001b[0m out \u001b[38;5;241m=\u001b[39m out[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\n",
      "File \u001b[0;32m~/anaconda3/envs/tl4pm/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/tl4pm/lib/python3.8/site-packages/torch/nn/modules/rnn.py:812\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_forward_args(\u001b[38;5;28minput\u001b[39m, hx, batch_sizes)\n\u001b[1;32m    811\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 812\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    813\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    815\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m    816\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 514.00 MiB (GPU 0; 23.66 GiB total capacity; 1.55 GiB already allocated; 438.44 MiB free; 2.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "torch_device, device_package = TorchUtils.get_torch_device()\n",
    "eval_model(model, target_test_set, torch_device,\n",
    "           device_package, decision_boundary=0.5,\n",
    "           weighted=False, print_res=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "23b080f8-51c4-418b-b57d-7e3b651d06d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc:  0.5922810364410246\n",
      "f1:  0.4702839183558161\n",
      "f1 inverse:  0.4069542183917134\n",
      "Precision:  0.8654471016376397\n",
      "Precision inverse:  0.2692941607367099\n",
      "Recall:  0.322864138867339\n",
      "Recall inverse:  0.8325380135878356\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5922810364410246,\n",
       " 0.4702839183558161,\n",
       " 0.4069542183917134,\n",
       " 0.8654471016376397,\n",
       " 0.2692941607367099,\n",
       " 0.322864138867339,\n",
       " 0.8325380135878356)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = CaseDataSet.CaseDataset(split_pattern=\"811split\", input_data=\"target\",\n",
    "                                  data_version=\"_test\", embedding_version=\"_w2v\",\n",
    "                                  earliness_requirement=True)\n",
    "\n",
    "model = torch.load(\"../../Model/811split/LSTM/LSTM_S_h128_l1_w2v.LSTM\")\n",
    "\n",
    "torch_device, device_package = TorchUtils.get_torch_device()\n",
    "eval_model(model, test_set, torch_device,\n",
    "           device_package, decision_boundary=0.5,\n",
    "           weighted=False, print_res=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892264d6-e296-47cb-97ff-551746bc66e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "186ad606-cc2b-4eb5-823a-73016e2d6ee7",
   "metadata": {},
   "source": [
    "## Scale Test Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5cdd7dd-df64-4d10-b112-4a069e37d3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "earliness_requirement = True\n",
    "folder_path = \"../../Data/Training/scale/\"\n",
    "torch_device, device_package = TorchUtils.get_torch_device()               \n",
    "onehot_test_set = CaseDataSet.CaseDataset(project_data_path=folder_path, split_pattern=\"\",\n",
    "                                          input_data=\"target\", data_version=\"_test_0.1\",\n",
    "                                          embedding_version=\"_onehot\",\n",
    "                                          earliness_requirement=earliness_requirement)\n",
    "\n",
    "w2v_test_set = CaseDataSet.CaseDataset(project_data_path=folder_path, split_pattern=\"\",\n",
    "                                          input_data=\"target\", data_version=\"_test_0.1\",\n",
    "                                          embedding_version=\"_w2v\",\n",
    "                                          earliness_requirement=earliness_requirement)\n",
    "\n",
    "st_test_set = CaseDataSet.CaseDataset(project_data_path=folder_path, split_pattern=\"\",\n",
    "                                          input_data=\"target\", data_version=\"_test_0.1\",\n",
    "                                          embedding_version=\"_st\",\n",
    "                                          earliness_requirement=earliness_requirement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6139037d-03af-461a-b0b5-5b7adaf1bcad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc:  0.5175080285380986\n",
      "weighted f1:  0.312198051705805\n",
      "weighted_precision:  0.7264766759561924\n",
      "weighted_recall:  0.37061929908785407\n",
      "===============================\n",
      "roc_auc:  0.5512496656698703\n",
      "weighted f1:  0.39574774242639305\n",
      "weighted_precision:  0.6918208893604325\n",
      "weighted_recall:  0.41569058816400917\n",
      "===============================\n",
      "roc_auc:  0.5914379810321482\n",
      "weighted f1:  0.369838378144881\n",
      "weighted_precision:  0.7091945116261374\n",
      "weighted_recall:  0.4023323343385427\n",
      "===============================\n"
     ]
    }
   ],
   "source": [
    "for i in [\"1\", \"2\", \"3\"]:\n",
    "    onehot_model = torch.load(\"../../Model/scale/LSTM/LSTM_T_h512_l1_st_0.01_\"+ i +\".LSTM\")\n",
    "    \n",
    "    eval_model(onehot_model, st_test_set,\n",
    "               torch_device, device_package,\n",
    "               decision_boundary=0.5, weighted=True, print_res=False)\n",
    "    print(\"===============================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6c3d9ae9-1989-45ff-b233-97991911ba43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc:  0.5753998742838414\n",
      "weighted f1:  0.6227065363623507\n",
      "weighted_precision:  0.601067508094824\n",
      "weighted_recall:  0.6795137707470088\n",
      "===============================\n",
      "roc_auc:  0.578643172315416\n",
      "weighted f1:  0.618504811563308\n",
      "weighted_precision:  0.597446957601968\n",
      "weighted_recall:  0.7011312101198328\n",
      "===============================\n",
      "roc_auc:  0.5442579729771531\n",
      "weighted f1:  0.6247718903482914\n",
      "weighted_precision:  0.6041613393570541\n",
      "weighted_recall:  0.6752350278957254\n",
      "===============================\n"
     ]
    }
   ],
   "source": [
    "for i in [\"1\", \"2\", \"3\"]:\n",
    "    onehot_model = torch.load(\"../../Model/scale/LSTM/LSTM_T_h512_l1_st_0.05_\"+ i +\".LSTM\")\n",
    "    \n",
    "    eval_model(onehot_model, st_test_set,\n",
    "               torch_device, device_package,\n",
    "               decision_boundary=0.5, weighted=True, print_res=False)\n",
    "    print(\"===============================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd2f48ec-87c4-46a0-a10e-2ae69983590f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc:  0.6242836105797538\n",
      "weighted f1:  0.45274668460436357\n",
      "weighted_precision:  0.7102840687353728\n",
      "weighted_recall:  0.457513202112338\n",
      "===============================\n",
      "roc_auc:  0.6294831762752706\n",
      "weighted f1:  0.4526514017268689\n",
      "weighted_precision:  0.7272652874133252\n",
      "weighted_recall:  0.460337731706976\n",
      "===============================\n",
      "roc_auc:  0.61830098603866\n",
      "weighted f1:  0.47726935907768736\n",
      "weighted_precision:  0.7068466721410711\n",
      "weighted_recall:  0.47480528923462706\n",
      "===============================\n"
     ]
    }
   ],
   "source": [
    "for i in [\"1\", \"2\", \"3\"]:\n",
    "    onehot_model = torch.load(\"../../Model/scale/LSTM/LSTM_T_h512_l1_st_0.1_\"+ i +\".LSTM\")\n",
    "    \n",
    "    eval_model(onehot_model, st_test_set,\n",
    "               torch_device, device_package,\n",
    "               decision_boundary=0.5, weighted=True, print_res=False)\n",
    "    print(\"===============================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04c86062-c8e4-4fd9-8733-16c95b25a480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc:  0.6140875915613313\n",
      "weighted f1:  0.5302700443381574\n",
      "weighted_precision:  0.6797786663222483\n",
      "weighted_recall:  0.5122652634130199\n",
      "===============================\n",
      "roc_auc:  0.6301521290353005\n",
      "weighted f1:  0.5756143749195455\n",
      "weighted_precision:  0.6746347592443788\n",
      "weighted_recall:  0.5527129000834309\n",
      "===============================\n",
      "roc_auc:  0.6441502602298125\n",
      "weighted f1:  0.6513411741836981\n",
      "weighted_precision:  0.6586725547586753\n",
      "weighted_recall:  0.6453304373359932\n",
      "===============================\n"
     ]
    }
   ],
   "source": [
    "for i in [\"1\", \"2\", \"3\"]:\n",
    "    onehot_model = torch.load(\"../../Model/scale/LSTM/LSTM_T_h512_l1_st_0.5_\"+ i +\".LSTM\")\n",
    "    \n",
    "    eval_model(onehot_model, st_test_set,\n",
    "               torch_device, device_package,\n",
    "               decision_boundary=0.5, weighted=True, print_res=False)\n",
    "    print(\"===============================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e917c632-edc8-4902-a3bf-50d2da259f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc:  0.5175080285380986\n",
      "weighted f1:  0.312198051705805\n",
      "weighted_precision:  0.7264766759561924\n",
      "weighted_recall:  0.37061929908785407\n",
      "===============================\n",
      "roc_auc:  0.5512496656698703\n",
      "weighted f1:  0.39574774242639305\n",
      "weighted_precision:  0.6918208893604325\n",
      "weighted_recall:  0.41569058816400917\n",
      "===============================\n",
      "roc_auc:  0.5914379810321482\n",
      "weighted f1:  0.369838378144881\n",
      "weighted_precision:  0.7091945116261374\n",
      "weighted_recall:  0.4023323343385427\n",
      "===============================\n",
      "finished test with scale:  0.01\n",
      "roc_auc:  0.5753998742838414\n",
      "weighted f1:  0.6227065363623507\n",
      "weighted_precision:  0.601067508094824\n",
      "weighted_recall:  0.6795137707470088\n",
      "===============================\n",
      "roc_auc:  0.578643172315416\n",
      "weighted f1:  0.618504811563308\n",
      "weighted_precision:  0.597446957601968\n",
      "weighted_recall:  0.7011312101198328\n",
      "===============================\n",
      "roc_auc:  0.5442579729771531\n",
      "weighted f1:  0.6247718903482914\n",
      "weighted_precision:  0.6041613393570541\n",
      "weighted_recall:  0.6752350278957254\n",
      "===============================\n",
      "finished test with scale:  0.05\n",
      "roc_auc:  0.6242836105797538\n",
      "weighted f1:  0.45274668460436357\n",
      "weighted_precision:  0.7102840687353728\n",
      "weighted_recall:  0.457513202112338\n",
      "===============================\n",
      "roc_auc:  0.6294831762752706\n",
      "weighted f1:  0.4526514017268689\n",
      "weighted_precision:  0.7272652874133252\n",
      "weighted_recall:  0.460337731706976\n",
      "===============================\n",
      "roc_auc:  0.61830098603866\n",
      "weighted f1:  0.47726935907768736\n",
      "weighted_precision:  0.7068466721410711\n",
      "weighted_recall:  0.47480528923462706\n",
      "===============================\n",
      "finished test with scale:  0.1\n",
      "roc_auc:  0.6140875915613313\n",
      "weighted f1:  0.5302700443381574\n",
      "weighted_precision:  0.6797786663222483\n",
      "weighted_recall:  0.5122652634130199\n",
      "===============================\n",
      "roc_auc:  0.6301521290353005\n",
      "weighted f1:  0.5756143749195455\n",
      "weighted_precision:  0.6746347592443788\n",
      "weighted_recall:  0.5527129000834309\n",
      "===============================\n",
      "roc_auc:  0.6441502602298125\n",
      "weighted f1:  0.6513411741836981\n",
      "weighted_precision:  0.6586725547586753\n",
      "weighted_recall:  0.6453304373359932\n",
      "===============================\n",
      "finished test with scale:  0.5\n"
     ]
    }
   ],
   "source": [
    "for scale in [\"0.01\", \"0.05\", \"0.1\", \"0.5\"]:\n",
    "    for i in [\"1\", \"2\", \"3\"]:\n",
    "        onehot_model = torch.load(\"../../Model/scale/LSTM/LSTM_T_h512_l1_st_\" + scale + \"_\"+ i +\".LSTM\")\n",
    "\n",
    "        eval_model(onehot_model, st_test_set,\n",
    "                   torch_device, device_package,\n",
    "                   decision_boundary=0.5, weighted=True, print_res=False)\n",
    "        print(\"===============================\")\n",
    "    print(\"finished test with scale: \", scale)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
