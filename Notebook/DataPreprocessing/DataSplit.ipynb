{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ff013cc-9f01-451a-845f-905c8aa4c835",
   "metadata": {},
   "source": [
    "# Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98e154d7-7196-4289-99d3-b4447631cea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import pickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1be023c9-7b30-4d7d-93b4-ea6a650ae77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_trace = pd.read_pickle(\"../../Data/Trace/source_trace_c_l.pkl\")\n",
    "target_trace = pd.read_pickle(\"../../Data/Trace/target_trace_c_l.pkl\")\n",
    "trace_dict = {\"source\": source_trace,\n",
    "              \"target\": target_trace}\n",
    "\n",
    "split_dict = {\"811split\": [0.8, 0.1, 0.1],\n",
    "              \"641620split\": [0.64, 0.16, 0.2]}\n",
    "\n",
    "order_dict = {\"sorted\": True,\n",
    "              \"random\": False}\n",
    "\n",
    "training_data_path = \"../../Data/Training/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c477e78-26ec-4dec-a80b-3c9aac06fe5b",
   "metadata": {},
   "source": [
    "## Split functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e21e7426-b4ae-40e7-9160-b41c6fc2b4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, ratio=[0.8, 0.1, 0.1], sort=True):\n",
    "    data_size = data.shape[0]\n",
    "    train_size = int(ratio[0] * data_size)\n",
    "    val_size = int(ratio[1] * data_size)\n",
    "    test_size = data_size - train_size - val_size\n",
    "    if sort:\n",
    "        data_sorted = data.sort_values(by='Start Time', ascending=True)\n",
    "    else:\n",
    "        data_sorted = data.sample(frac=1)\n",
    "    data_train = data_sorted[:train_size]\n",
    "    data_val = data_sorted[train_size: train_size+val_size]\n",
    "    data_test = data_sorted[train_size+val_size:]\n",
    "    return {\"train\": data_train,\n",
    "            \"val\": data_val,\n",
    "            \"test\": data_test}\n",
    "\n",
    "\n",
    "def split_data_alt(data, ratio=[0.8, 0.1, 0.1]):\n",
    "    data_size = data.shape[0]\n",
    "    train_size = int(ratio[0] * data_size)\n",
    "    test_size = int(ratio[2] * data_size)\n",
    "    data_sorted = data.sort_values(by='Start Time', ascending=True)\n",
    "    data_test = data_sorted[-test_size:]   \n",
    "    data_rest = data_sorted[:-test_size]\n",
    "    data_rest = data_rest.sample(frac=1)\n",
    "    data_train = data_rest[:train_size]\n",
    "    data_val = data_rest[train_size:]\n",
    "    return {\"train\": data_train,\n",
    "            \"val\": data_val,\n",
    "            \"test\": data_test}\n",
    "\n",
    "\n",
    "def split_data_scale_test(data, test_ratio=0.2, scale=0.1, train_ratio=0.8, sort=True):\n",
    "    data_size = data.shape[0]\n",
    "    scale_size = int(scale * data_size)\n",
    "    test_size = int(test_ratio * data_size)\n",
    "    train_size = int(train_ratio * scale_size)\n",
    "    if sort:\n",
    "        data_sorted = data.sort_values(by='Start Time', ascending=True)\n",
    "    else:\n",
    "        data_sorted = data.sample(frac=1)\n",
    "    data_test = data_sorted[-test_size:]\n",
    "    data_rest = data_sorted[:scale_size]\n",
    "    data_train = data_rest[:train_size]\n",
    "    data_val = data_rest[train_size:]\n",
    "    return {\"train\": data_train,\n",
    "            \"val\": data_val,\n",
    "            \"test\": data_test}\n",
    "\n",
    "\n",
    "def split_data_scale_test_alt(data, test_ratio=0.2, scale=0.1, train_ratio=0.8):\n",
    "    data_size = data.shape[0]\n",
    "    scale_size = int(scale * data_size)\n",
    "    test_size = int(test_ratio * data_size)\n",
    "    train_size = int(train_ratio * scale_size)\n",
    "    data_sorted = data.sort_values(by='Start Time', ascending=True)\n",
    "    data_test = data_sorted[-test_size:]\n",
    "    data_rest = data_sorted[:scale_size]\n",
    "    data_rest = data_rest.sample(frac=1)\n",
    "    data_train = data_rest[:train_size]\n",
    "    data_val = data_rest[train_size:]\n",
    "    return {\"train\": data_train,\n",
    "            \"val\": data_val,\n",
    "            \"test\": data_test}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db05e94-6165-492a-ab90-7974aeed797a",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "279afee1-fd22-43cf-a130-a385dd8057eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sorting in order_dict:\n",
    "    for split_pattern in split_dict:\n",
    "        for trace_type in trace_dict:\n",
    "            data_sets = split_data(trace_dict[trace_type],\n",
    "                                   ratio=split_dict[split_pattern],\n",
    "                                   sort=order_dict[sorting])\n",
    "            for single_set in data_sets:\n",
    "                file_name = \"_\".join([trace_type, single_set, sorting + \".pkl\"])\n",
    "                data_sets[single_set].to_pickle(training_data_path + split_pattern + \"/\" + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "182a8e6c-cf97-4708-90dd-9d57c0d421f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for split_pattern in split_dict:\n",
    "    for trace_type in trace_dict:\n",
    "        data_sets = split_data_alt(trace_dict[trace_type],\n",
    "                                   ratio=split_dict[split_pattern],\n",
    "                                   sort=order_dict[sorting])\n",
    "        for single_set in data_sets:\n",
    "            file_name = \"_\".join([trace_type, single_set, \"alt.pkl\"])\n",
    "            data_sets[single_set].to_pickle(training_data_path + split_pattern + \"/\" + file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d701e5-5ff7-407d-b7f9-288d836c4e6f",
   "metadata": {},
   "source": [
    "## Scale test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ab0a069e-cc6a-447f-ae27-8ef3aaf3512f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_list = [0.01, 0.05, 0.1, 0.5]\n",
    "training_data_path = \"../../Data/Training/scale/\"\n",
    "for scale in scale_list:\n",
    "    for trace_type in trace_dict:\n",
    "        data_sets = split_data_scale_test(trace_dict[trace_type], test_ratio=0.2, scale=scale,\n",
    "                                          train_ratio=0.8, sort=True)\n",
    "        for single_set in data_sets:\n",
    "                file_name = \"_\".join([trace_type, single_set, str(scale) + \".pkl\"])\n",
    "                data_sets[single_set].to_pickle(training_data_path + file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
